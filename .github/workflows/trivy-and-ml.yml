name: trivy-and-ml

on:
  push:
    branches: [ main, hybrid_operator ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:
    inputs:
      mode:
        description: "pipeline = normal Trivy+ML run; sv_trivy = repeated Trivy validation + summary CSV; sv_ml = ML K-fold CV validation + summary CSV; sv_gate = full hybrid decision validation (Trivy+ML+Gate) + summary CSV"
        required: true
        default: "pipeline"

      # --- sv_trivy inputs ---
      runs:
        description: "Runs per profile for sv_trivy"
        required: false
        default: "10"
      profiles:
        description: "Profiles for sv_trivy (comma-separated)"
        required: false
        default: "low,medium,high"

      # --- sv_ml inputs ---
      ml_folds:
        description: "K folds for sv_ml"
        required: false
        default: "5"
      ml_seeds:
        description: "Seeds for sv_ml (comma-separated)"
        required: false
        default: "42,43,44"
      ml_contam:
        description: "Contamination for sv_ml (Isolation Forest)"
        required: false
        default: "0.05"

      # --- sv_gate inputs (NEW) ---
      gate_runs:
        description: "Runs per profile for sv_gate"
        required: false
        default: "10"
      gate_profiles:
        description: "Profiles for sv_gate (comma-separated)"
        required: false
        default: "clean,low,medium,high"
      gate_ml_contam:
        description: "ML contamination for sv_gate"
        required: false
        default: "0.005"

concurrency:
  group: trivy-and-ml-${{ github.event.pull_request.number || github.ref }}-${{ github.event.inputs.mode || 'pipeline' }}
  cancel-in-progress: true

permissions:
  contents: read
  actions: write
  pull-requests: write

jobs:
  trivy_eval_and_ml:
    # Run on push/PR as usual. If manually triggered, run only when mode == pipeline
    if: ${{ github.event_name != 'workflow_dispatch' || github.event.inputs.mode == 'pipeline' }}
    runs-on: ubuntu-latest
    env:
      PYTHON_VERSION: '3.12'

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Git LFS Pull
        run: git lfs pull

      - name: Debug - Check LFS file status
        run: |
          echo "File size check"
          ls -lh ml/models/isolation_forest_model_v1.pkl || true
          echo ""
          echo "First 5 lines of file (should be binary gibberish)"
          head -n 5 ml/models/isolation_forest_model_v1.pkl || echo "Binary file or missing"
          echo ""
          echo "LFS status"
          git lfs ls-files || true

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Python deps (ML only)
        run: |
          if [ -f ml/requirements.txt ]; then pip install -r ml/requirements.txt; fi

      - name: Prepare dirs
        run: |
          rm -rf datasets trivy_out artifacts ml_out validation
          mkdir -p datasets trivy_out artifacts ml_out validation
          echo "Cleaned and recreated output directories"

      - name: Generate payment set
        env:
          INJECT_PROFILE: medium
        run: |
          python trivy/make_payment_set_trivy.py --id 0001 --template trivy/payment_set_template
          echo "Generated -> datasets/payment_set_0001"

      - name: Show generated tree (debug)
        run: ls -R datasets/payment_set_0001

      - name: Debug - Show ground truth CSV
        run: |
          echo "Ground Truth CSV"
          cat datasets/payment_set_0001/ground_truth/secrets.csv
          echo ""
          echo "Count of secrets in ground truth"
          tail -n +2 datasets/payment_set_0001/ground_truth/secrets.csv | wc -l

      - name: Debug - Verify injected secrets in files
        run: |
          echo "Checking Dockerfile for injected secrets"
          cat datasets/payment_set_0001/Dockerfile | grep -E "AKIA|sk_test_|postgres://|eyJhbGc" || echo "No secrets found in Dockerfile"
          echo ""
          echo "Checking config.yml for injected secrets"
          cat datasets/payment_set_0001/configs/config.yml | grep -E "sk_test_|postgres://" || echo "No secrets found in config.yml"

      - name: Install Trivy (official script)
        run: |
          curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh
          ./bin/trivy --version

      - name: Trivy filesystem scan (JSON for scoring)
        run: |
          ./bin/trivy fs --scanners secret \
            --format json -o trivy_out/scan.json datasets/payment_set_0001 || true

      - name: Debug - Show Trivy findings
        run: |
          echo "Raw Trivy Results"
          SECRET_COUNT=$(cat trivy_out/scan.json | jq '[.Results[]?.Secrets // []] | flatten | length' 2>/dev/null || echo "0")

          if [ "$SECRET_COUNT" = "0" ] || [ "$SECRET_COUNT" = "null" ]; then
            echo "No secrets detected by Trivy"
            SECRET_COUNT="0"
          else
            echo "Found $SECRET_COUNT secrets:"
            cat trivy_out/scan.json | jq '.Results[] | select(.Secrets != null) | {Target, SecretCount: (.Secrets | length), Secrets: [.Secrets[] | {Title, RuleID, Severity, Match: .Match}]}' || true
          fi

          echo ""
          echo "Total Trivy detections: $SECRET_COUNT"

      - name: Trivy filesystem scan with low severity vulnerability
        run: |
          ./bin/trivy fs --scanners secret \
            --format json -o trivy_out/scan_low_severity.json datasets/payment_set_0001 || true

      - name: Trivy filesystem scan (SARIF artifact)
        run: |
          ./bin/trivy fs --scanners secret,misconfig \
            --format sarif -o artifacts/0001_trivy.sarif datasets/payment_set_0001 || true

      - name: Score Trivy (Precision/Recall/F1 + risk -> JSON)
        run: |
          python trivy/score_trivy.py \
            --scan trivy_out/scan.json \
            --gt-csv datasets/payment_set_0001/ground_truth/secrets.csv \
            --out trivy_out/trivy_metrics.json
          echo "Trivy metrics"
          cat trivy_out/trivy_metrics.json

      - name: Debug - Trivy metrics interpretation
        run: |
          echo "Trivy Performance Summary"
          cat trivy_out/trivy_metrics.json | jq '{
            risk: .risk,
            critical: .critical,
            TP: .TP,
            FP: .FP,
            FN: .FN,
            precision: .precision,
            recall: .recall,
            f1: .f1
          }'

      - name: Verify Isolation Forest model exists
        run: |
          test -f ml/models/isolation_forest_model_v1.pkl || (echo "Model not found: ml/models/isolation_forest_model_v1.pkl. Run ml/src/train.py and commit the .pkl."; exit 1)

      - name: ML Evaluate (Isolation Forest on eval.csv)
        env:
          ML_DECISION_MODE: bestf1
          ML_CONTAM: "0.05"
        run: |
          python ml/src/evaluate.py
          echo "ML metrics"
          cat ml_out/ml_metrics.json

      - name: Decision Gate (compare Trivy + ML)
        run: |
          python ml/src/decision_gate.py
          echo "Gate output"
          cat ml_out/gate_out.json

      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: trivy-and-ml-artifacts
          path: |
            artifacts/**
            trivy_out/**
            ml_out/**

      - name: Post Job Summary
        if: always()
        run: |
          {
            echo "## Trivy + ML Summary"
            echo

            echo "### Trivy Metrics"
            if [ -f trivy_out/trivy_metrics.json ]; then
              echo '```json'
              cat trivy_out/trivy_metrics.json | jq '{
                risk: .risk,
                critical: .critical,
                TP: .TP,
                FP: .FP,
                FN: .FN,
                precision: .precision,
                recall: .recall,
                f1: .f1
              }'
              echo '```'
            else
              echo "_trivy_out/trivy_metrics.json not found_"
            fi

            echo
            echo "### ML Metrics"
            if [ -f ml_out/ml_metrics.json ]; then
              echo '```json'
              cat ml_out/ml_metrics.json
              echo '```'
            else
              echo "_ml_out/ml_metrics.json not found_"
            fi

            echo
            echo "### Decision Gate"
            if [ -f ml_out/gate_out.json ]; then
              echo '```json'
              cat ml_out/gate_out.json
              echo '```'
            else
              echo "_ml_out/gate_out.json not found_"
            fi
          } >> "$GITHUB_STEP_SUMMARY"

  sv_trivy_validation:
    # Manual-only job: repeated trials for low/medium/high and produces summary CSV
    if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.mode == 'sv_trivy' }}
    runs-on: ubuntu-latest
    env:
      PYTHON_VERSION: '3.12'

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install Trivy (official script) and add to PATH
        run: |
          curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh
          ./bin/trivy --version
          echo "$PWD/bin" >> $GITHUB_PATH

      - name: Prepare dirs for SV runs
        run: |
          rm -rf datasets validation/trivy_runs validation/summary
          mkdir -p datasets validation/trivy_runs validation/summary

      - name: Run SV trials (low/medium/high) + summarize
        run: |
          RUNS="${{ github.event.inputs.runs }}"
          PROFILES="${{ github.event.inputs.profiles }}"
          python validation/run_trivy_trials.py --runs "${RUNS:-10}" --profiles "${PROFILES:-low,medium,high}"
          python validation/summarize_trivy.py

      - name: Upload SV summary artifact
        uses: actions/upload-artifact@v4
        with:
          name: sv-trivy-summary
          path: |
            validation/summary/trivy_summary.csv
            validation/summary/trivy_runs_detailed.csv

  sv_ml_validation:
    # Manual-only job: ML K-fold CV validation + summary CSV
    if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.mode == 'sv_ml' }}
    runs-on: ubuntu-latest
    env:
      PYTHON_VERSION: '3.12'

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Git LFS Pull
        run: git lfs pull

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Python deps (ML)
        run: |
          if [ -f ml/requirements.txt ]; then pip install -r ml/requirements.txt; fi
          python -c "import pandas, numpy, sklearn" || pip install pandas numpy scikit-learn

      - name: Prepare dirs for ML validation
        run: |
          rm -rf validation/ml_runs validation/summary
          mkdir -p validation/ml_runs validation/summary

      - name: Run ML K-fold cross-validation + summarize
        run: |
          FOLDS="${{ github.event.inputs.ml_folds }}"
          SEEDS="${{ github.event.inputs.ml_seeds }}"
          CONTAM="${{ github.event.inputs.ml_contam }}"
          python validation/run_ml_cv_trials.py --folds "${FOLDS:-5}" --seeds "${SEEDS:-42,43,44}" --contam "${CONTAM:-0.05}"
          python validation/summarize_ml.py
          echo "Validation outputs:"
          ls -R validation || true

      - name: Upload ML validation artifact
        uses: actions/upload-artifact@v4
        with:
          name: sv-ml-validation
          path: |
            validation/ml_runs/ml_runs_detailed.csv
            validation/summary/ml_summary.csv
            validation/summary/ml_by_seed.csv

  sv_gate_validation:
    # Manual-only job: full hybrid decision validation (Trivy + ML + Gate)
    if: ${{ github.event_name == 'workflow_dispatch' && github.event.inputs.mode == 'sv_gate' }}
    runs-on: ubuntu-latest
    env:
      PYTHON_VERSION: '3.12'

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          lfs: true

      - name: Git LFS Pull
        run: git lfs pull

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'

      - name: Install Python deps (ML)
        run: |
          if [ -f ml/requirements.txt ]; then pip install -r ml/requirements.txt; fi
          python -c "import pandas, numpy, sklearn" || pip install pandas numpy scikit-learn

      - name: Install Trivy (official script) and add to PATH
        run: |
          curl -sfL https://raw.githubusercontent.com/aquasecurity/trivy/main/contrib/install.sh | sh
          ./bin/trivy --version
          echo "$PWD/bin" >> $GITHUB_PATH

      - name: Prepare dirs for Gate validation
        run: |
          rm -rf validation/gate_runs validation/summary datasets trivy_out ml_out artifacts
          mkdir -p validation/gate_runs validation/summary

      - name: Run Hybrid Gate trials + summarize
        run: |
          RUNS="${{ github.event.inputs.gate_runs }}"
          PROFILES="${{ github.event.inputs.gate_profiles }}"
          CONTAM="${{ github.event.inputs.gate_ml_contam }}"
          python validation/run_gate_trials.py --runs "${RUNS:-10}" --profiles "${PROFILES:-clean,low,medium,high}" --ml_contam "${CONTAM:-0.005}"
          python validation/summarize_gate.py
          echo "Outputs:"
          ls -R validation || true

      - name: Upload Hybrid Gate validation artifact
        uses: actions/upload-artifact@v4
        with:
          name: sv-gate-validation
          path: |
            validation/gate_runs/**
            validation/summary/**